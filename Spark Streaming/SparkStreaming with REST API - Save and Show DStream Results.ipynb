{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://datanoon.com/blog/loading_data_rest_api_to_spark/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# Create a local StreamingContext with batch interval of 1 seconds\n",
    "conf = SparkConf().setAppName(\"app1\").setMaster(\"local\")\n",
    "sc = SparkContext(conf=conf)\n",
    "ssc = StreamingContext(sc, 1)\n",
    "sqlContext = SQLContext(sc)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather():\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/weather?q=barcelona&appid=24b234cb23d2bddfc71ee6db0e1b1d6c\"\n",
    "    response = requests.get(url)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the queue through which RDDs can be pushed to\n",
    "# a QueueInputDStream\n",
    "num_measurements = 6\n",
    "interval = 10 # interval between calls to API in seconds\n",
    "\n",
    "calls = []\n",
    "rddQueue = []\n",
    "for i in range(num_measurements):\n",
    "    time.sleep(interval)\n",
    "    weather = get_weather()\n",
    "    rddQueue += [ssc.sparkContext.parallelize([weather.text])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/35245648/how-to-convert-spark-streaming-data-into-spark-dataframe/50894876#50894876\n",
    "def process_stream(record, spark, queries):\n",
    "    if not record.isEmpty():\n",
    "        df = spark.read.json(record) \n",
    "        df.show()\n",
    "        queries.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "|    base|clouds|cod|        coord|        dt|     id|                main|     name|                 sys|timezone|visibility|             weather|      wind|\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "|stations|  [20]|200|[41.39, 2.16]|1607292088|3128760|[277.39, 61, 1005...|Barcelona|[ES, 6398, 160723...|    3600|     10000|[[few clouds, 02n...|[340, 3.1]|\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "|    base|clouds|cod|        coord|        dt|     id|                main|     name|                 sys|timezone|visibility|             weather|      wind|\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "|stations|  [20]|200|[41.39, 2.16]|1607292088|3128760|[277.39, 61, 1005...|Barcelona|[ES, 6398, 160723...|    3600|     10000|[[few clouds, 02n...|[340, 3.1]|\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "|    base|clouds|cod|        coord|        dt|     id|                main|     name|                 sys|timezone|visibility|             weather|      wind|\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "|stations|  [20]|200|[41.39, 2.16]|1607292088|3128760|[277.39, 61, 1005...|Barcelona|[ES, 6398, 160723...|    3600|     10000|[[few clouds, 02n...|[340, 3.1]|\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "|    base|clouds|cod|        coord|        dt|     id|                main|     name|                 sys|timezone|visibility|             weather|      wind|\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "|stations|  [20]|200|[41.39, 2.16]|1607292088|3128760|[277.39, 61, 1005...|Barcelona|[ES, 6398, 160723...|    3600|     10000|[[few clouds, 02n...|[340, 3.1]|\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "|    base|clouds|cod|        coord|        dt|     id|                main|     name|                 sys|timezone|visibility|             weather|      wind|\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "|stations|  [20]|200|[41.39, 2.16]|1607292088|3128760|[277.39, 61, 1005...|Barcelona|[ES, 6398, 160723...|    3600|     10000|[[few clouds, 02n...|[340, 3.1]|\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "|    base|clouds|cod|        coord|        dt|     id|                main|     name|                 sys|timezone|visibility|             weather|      wind|\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "|stations|  [20]|200|[41.39, 2.16]|1607292088|3128760|[277.39, 61, 1005...|Barcelona|[ES, 6398, 160723...|    3600|     10000|[[few clouds, 02n...|[340, 3.1]|\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/36421619/whats-the-meaning-of-dstream-foreachrdd-function\n",
    "\n",
    "# Create a DStream (\"discretized stream\") called inputStream, an abstraction that breaks a continuous stream \n",
    "# of data into small chunks\n",
    "inputStream = ssc.queueStream(rddQueue)\n",
    "queries = []\n",
    "# save output to textfile\n",
    "inputStream.saveAsTextFiles('streaming_weather')\n",
    "# show output on display\n",
    "inputStream.foreachRDD(lambda rdd: process_stream(rdd, spark, queries))\n",
    "\n",
    "ssc.start()\n",
    "time.sleep(num_measurements)\n",
    "ssc.stop(stopSparkContext=True, stopGraceFully=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
