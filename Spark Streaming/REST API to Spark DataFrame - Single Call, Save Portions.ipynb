{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://datanoon.com/blog/loading_data_rest_api_to_spark/\n",
    "\n",
    "# Makes a call to a REST API and converts the resulting JSON to a Spark DF\n",
    "# All of the save commands in this file save to a folder rather than straigh to a .csv file\n",
    "# Can save components of the JSON, but not the whole thing due to complex data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "conf = SparkConf().setAppName(\"app1\").setMaster(\"local\")\n",
    "sc = SparkContext('local', 'CurrentWeather')\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to make the call to the REST API service\n",
    "def get_weather():\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/weather?q=barcelona&appid=24b234cb23d2bddfc71ee6db0e1b1d6c\"\n",
    "    response = requests.get(url)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"coord\":{\"lon\":2.16,\"lat\":41.39},\"weather\":[{\"id\":801,\"main\":\"Clouds\",\"description\":\"few clouds\",\"icon\":\"02n\"}],\"base\":\"stations\",\"main\":{\"temp\":281.31,\"feels_like\":277.32,\"temp_min\":279.82,\"temp_max\":282.59,\"pressure\":1005,\"humidity\":61},\"visibility\":10000,\"wind\":{\"speed\":3.1,\"deg\":340},\"clouds\":{\"all\":20},\"dt\":1607292749,\"sys\":{\"type\":1,\"id\":6398,\"country\":\"ES\",\"sunrise\":1607238205,\"sunset\":1607271720},\"timezone\":3600,\"id\":3128760,\"name\":\"Barcelona\",\"cod\":200}\n"
     ]
    }
   ],
   "source": [
    "weather = get_weather()\n",
    "print(weather.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "|    base|clouds|cod|        coord|        dt|     id|                main|     name|                 sys|timezone|visibility|             weather|      wind|\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "|stations|  [20]|200|[41.39, 2.16]|1607292749|3128760|[277.32, 61, 1005...|Barcelona|[ES, 6398, 160723...|    3600|     10000|[[few clouds, 02n...|[340, 3.1]|\n",
      "+--------+------+---+-------------+----------+-------+--------------------+---------+--------------------+--------+----------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Covert json to rdd, and then to df\n",
    "json_rdd = sc.parallelize([weather.text])\n",
    "json_df = spark.read.json(json_rdd)\n",
    "json_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://api.openweathermap.org/data/2.5/weather?q=London,uk&APPID=24b234cb23d2bddfc71ee6db0e1b1d6c\n",
    "# https://stackoverflow.com/questions/50350496/apache-spark-cant-save-grouped-data-as-csv\n",
    "\n",
    "# columns = [base, clouds, cod, coord, dt, id, main, name, sys, timezone, visibility, weather, wind]\n",
    "\n",
    "# Save select results of API call to .csv \n",
    "json_df.select(\n",
    "    'main.temp',\n",
    "    'main.temp_min',\n",
    "    'main.temp_max',\n",
    "    'main.pressure',\n",
    "    'main.humidity',\n",
    "    'wind.speed',\n",
    "    'wind.deg',\n",
    "    'clouds.all',\n",
    ").write.option(\"header\", \"true\").csv(\"current_weather_csv\")\n",
    "\n",
    "# Save all results of API call to text file\n",
    "json_df.rdd.saveAsTextFile('current_weather_text')\n",
    "\n",
    "# Attempt to save all results of API call to CSV file \n",
    "# Error: AnalysisException: 'CSV data source does not support struct<all:bigint> data type.;'\n",
    "# json_df.write.option(\"header\", \"true\").csv(\"TEST.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+------+--------+--------+\n",
      "|feels_like|humidity|pressure|  temp|temp_max|temp_min|\n",
      "+----------+--------+--------+------+--------+--------+\n",
      "|    277.32|      61|    1005|281.31|  282.59|  279.82|\n",
      "+----------+--------+--------+------+--------+--------+\n",
      "\n",
      "+-----------+----+---+------+\n",
      "|description|icon| id|  main|\n",
      "+-----------+----+---+------+\n",
      "| few clouds| 02n|801|Clouds|\n",
      "+-----------+----+---+------+\n",
      "\n",
      "+---+-----+\n",
      "|deg|speed|\n",
      "+---+-----+\n",
      "|340|  3.1|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://datanoon.com/blog/loading_data_rest_api_to_spark/\n",
    "\n",
    "# Select only parts of the JSON request and save into dataframe\n",
    "# This method allows us to see and save the nested components of the JSON, though \n",
    "# only one stuct at a time\n",
    "\n",
    "rel_data = json.dumps(weather.json()['main'])\n",
    "weather_rdd = sc.parallelize([rel_data])\n",
    "weather_df = spark.read.json(weather_rdd)\n",
    "weather_df.show()\n",
    "weather_df.write.option(\"header\", \"true\").csv(\"rel_data_csv\")\n",
    "\n",
    "rel_data1 = json.dumps(weather.json()['weather'])\n",
    "weather_rdd1 = sc.parallelize([rel_data1])\n",
    "weather_df1 = spark.read.json(weather_rdd1)\n",
    "weather_df1.show()\n",
    "\n",
    "rel_data2 = json.dumps(weather.json()['wind'])\n",
    "weather_rdd2 = sc.parallelize([rel_data2])\n",
    "weather_df2 = spark.read.json(weather_rdd2)\n",
    "weather_df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
